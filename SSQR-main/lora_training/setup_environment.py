#!/usr/bin/env python3
"""
ç¯å¢ƒè®¾ç½®è„šæœ¬
ç”¨äºè®¾ç½®RQ-VAE LoRAè®­ç»ƒç¯å¢ƒ
"""

import os
import subprocess
import sys
from pathlib import Path


def run_command(command, description):
    """è¿è¡Œå‘½ä»¤å¹¶å¤„ç†é”™è¯¯"""
    print(f"\n{'='*50}")
    print(f"æ‰§è¡Œ: {description}")
    print(f"å‘½ä»¤: {command}")
    print('='*50)
    
    try:
        result = subprocess.run(command, shell=True, check=True, capture_output=True, text=True)
        print("âœ… æˆåŠŸ!")
        if result.stdout:
            print("è¾“å‡º:", result.stdout)
        return True
    except subprocess.CalledProcessError as e:
        print("âŒ å¤±è´¥!")
        print("é”™è¯¯:", e.stderr)
        return False


def check_cuda():
    """æ£€æŸ¥CUDAç¯å¢ƒ"""
    print("\nğŸ” æ£€æŸ¥CUDAç¯å¢ƒ...")
    
    try:
        import torch
        if torch.cuda.is_available():
            print(f"âœ… CUDAå¯ç”¨: {torch.cuda.get_device_name(0)}")
            print(f"   CUDAç‰ˆæœ¬: {torch.version.cuda}")
            print(f"   GPUæ•°é‡: {torch.cuda.device_count()}")
            return True
        else:
            print("âŒ CUDAä¸å¯ç”¨")
            return False
    except ImportError:
        print("âŒ PyTorchæœªå®‰è£…")
        return False


def install_requirements():
    """å®‰è£…ä¾èµ–åŒ…"""
    print("\nğŸ“¦ å®‰è£…ä¾èµ–åŒ…...")
    
    requirements_file = Path(__file__).parent / "requirements.txt"
    if not requirements_file.exists():
        print("âŒ requirements.txtæ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    return run_command(
        f"pip install -r {requirements_file}",
        "å®‰è£…Pythonä¾èµ–åŒ…"
    )


def setup_wandb():
    """è®¾ç½®Wandb"""
    print("\nğŸ”§ è®¾ç½®Wandb...")
    
    wandb_key = input("è¯·è¾“å…¥Wandb API Key (å¯é€‰ï¼Œç›´æ¥å›è½¦è·³è¿‡): ").strip()
    if wandb_key:
        return run_command(
            f"wandb login {wandb_key}",
            "ç™»å½•Wandb"
        )
    else:
        print("â­ï¸  è·³è¿‡Wandbè®¾ç½®")
        return True


def create_directories():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    print("\nğŸ“ åˆ›å»ºç›®å½•ç»“æ„...")
    
    directories = [
        "lora_data",
        "lora_outputs", 
        "checkpoints",
        "logs",
        "results"
    ]
    
    base_dir = Path(__file__).parent
    
    for dir_name in directories:
        dir_path = base_dir / dir_name
        dir_path.mkdir(exist_ok=True)
        print(f"âœ… åˆ›å»ºç›®å½•: {dir_path}")
    
    return True


def test_imports():
    """æµ‹è¯•å…³é”®åŒ…çš„å¯¼å…¥"""
    print("\nğŸ§ª æµ‹è¯•åŒ…å¯¼å…¥...")
    
    packages = [
        ("torch", "PyTorch"),
        ("transformers", "Transformers"),
        ("peft", "PEFT"),
        ("accelerate", "Accelerate"),
        ("wandb", "Wandb"),
        ("numpy", "NumPy"),
        ("pandas", "Pandas")
    ]
    
    failed_imports = []
    
    for package, name in packages:
        try:
            __import__(package)
            print(f"âœ… {name}")
        except ImportError as e:
            print(f"âŒ {name}: {e}")
            failed_imports.append(name)
    
    if failed_imports:
        print(f"\nâŒ ä»¥ä¸‹åŒ…å¯¼å…¥å¤±è´¥: {', '.join(failed_imports)}")
        return False
    else:
        print("\nâœ… æ‰€æœ‰åŒ…å¯¼å…¥æˆåŠŸ!")
        return True


def setup_huggingface():
    """è®¾ç½®Hugging Face"""
    print("\nğŸ¤— è®¾ç½®Hugging Face...")
    
    hf_token = input("è¯·è¾“å…¥Hugging Face Token (ç”¨äºä¸‹è½½LLaMA2ï¼Œå¯é€‰): ").strip()
    if hf_token:
        return run_command(
            f"huggingface-cli login --token {hf_token}",
            "ç™»å½•Hugging Face"
        )
    else:
        print("â­ï¸  è·³è¿‡Hugging Faceè®¾ç½®")
        print("ğŸ’¡ æç¤º: å¦‚æœéœ€è¦ä¸‹è½½LLaMA2æ¨¡å‹ï¼Œè¯·æ‰‹åŠ¨è®¾ç½®Hugging Face Token")
        return True


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ RQ-VAE LoRAè®­ç»ƒç¯å¢ƒè®¾ç½®")
    print("="*50)
    
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    if sys.version_info < (3, 8):
        print("âŒ éœ€è¦Python 3.8æˆ–æ›´é«˜ç‰ˆæœ¬")
        sys.exit(1)
    
    print(f"âœ… Pythonç‰ˆæœ¬: {sys.version}")
    
    # æ‰§è¡Œè®¾ç½®æ­¥éª¤
    steps = [
        ("åˆ›å»ºç›®å½•", create_directories),
        ("å®‰è£…ä¾èµ–", install_requirements),
        ("æ£€æŸ¥CUDA", check_cuda),
        ("è®¾ç½®Hugging Face", setup_huggingface),
        ("è®¾ç½®Wandb", setup_wandb),
        ("æµ‹è¯•å¯¼å…¥", test_imports)
    ]
    
    failed_steps = []
    
    for step_name, step_func in steps:
        if not step_func():
            failed_steps.append(step_name)
    
    # æ€»ç»“
    print("\n" + "="*50)
    print("ğŸ¯ ç¯å¢ƒè®¾ç½®å®Œæˆ!")
    
    if failed_steps:
        print(f"âŒ ä»¥ä¸‹æ­¥éª¤å¤±è´¥: {', '.join(failed_steps)}")
        print("è¯·æ‰‹åŠ¨è§£å†³è¿™äº›é—®é¢˜åé‡æ–°è¿è¡Œ")
    else:
        print("âœ… æ‰€æœ‰æ­¥éª¤éƒ½æˆåŠŸå®Œæˆ!")
        print("\nğŸ“‹ ä¸‹ä¸€æ­¥:")
        print("1. å‡†å¤‡RQ-VAEä»£ç æ•°æ®")
        print("2. è¿è¡Œ dataset_generator.py ç”Ÿæˆè®­ç»ƒæ•°æ®")
        print("3. è¿è¡Œ train_lora.py å¼€å§‹è®­ç»ƒ")
        print("4. è¿è¡Œ inference.py æµ‹è¯•æ¨¡å‹")
    
    print("="*50)


if __name__ == "__main__":
    main()
